


eval: 
  datasets: 
    - "gardenspointwalking"
  methods: 
    - "netvlad"
  partition: "test"
  device: "cpu"
  input_size: [480, 640, 3]
  distance: "l2" # either l2 or cosine
  
run: 
  datasets: 
    - "gardenspointwalking"
  methods: 
    - "netvlad"
    - "cosplace"
    - "amosnet"
    - "hybridnet" 
    - "mixvpr"
    - "calc"
  partition: "test"
  num_workers: 0
  pin_memory: False
  batch_size: 10
  device: None

train: 
  ######################## High Level Training Configuration ########################
  seed: 0 # random seed
  training_type: "contrastive" # training type either contrastive or asymmetric_distillation
  dataset_name: "mapillary_sls" # Dataset to train on

  method: "resnet50_gem" # method to train
  train_batch_size: 32 # training batch size
  infer_batch_size: 20 # inference batch size 
  learning_rate: 0.03 # learning rate
  device: "cuda" # either cpu or cuda for acceleration
  num_workers: 12 # number of workers for the dataloader
  max_epochs: 10000 # maximum number of allowable epochs
  patience: 3 # patience for early stopping
  datasets_folder: "/home/oliver/Documents/github/Datasets" # path to all the datasets
  #datasets_folder: "/Users/olivergrainge/Documents/github/lightweight_VPR/datasets_vg/datasets"
  recall_values: [1, 3, 5, 10, 20]


  ######################## Contrastive Training Configuration #########################
  cache_refresh_rate: 1000 # number of triplets per epoch
  train_positive_dist_threshold: 10
  val_positive_dist_threshold: 25
  neg_num_per_query: 10 # number of negative images per triplet
  mining: "partial" # either partial or random. Partial mines the hardest negatives, random mines random negatives. 
  loss_distance: "l2" # either cosine or l2
  margin: 0.1 # margin of the triplet loss
  val_check_interval: 5 # how many epochs before performing validation


  ######################## Contrastive GSV Training Configuration #####################
  layers_to_freeze: 1
  layers_to_crop: []
  optimizer: "sgd"
  weight_decay: 0.001 
  momentum: 0.9
  warmup_steps: 500
  milestones: [5, 10, 15]
  lr_mult: 0.3
  loss_name: "MultiSimilarityLoss"
  miner_name: "MultiSimilarityMiner"
  miner_margin: 0.1
  faiss_gpu: False
  pretrained: True

  img_per_place: 4
  min_img_per_place: 4
  cities: ["all"]
  #cities: ["London"]
  shuffle_all: False
  random_sample_from_each_place: True
  image_size: [320, 320]
  num_workers: 12
  show_data_stats: True
  val_set_names: ["pitts30k_val", "essex3in1_val", "sped_val", "inria_val", "crossseason_val"]
  batch_sampler: None

  ###################### Asymmetric Training Configuration ############################
  student_method: "resnet18_gem"
  teacher_method: "resnet18_gem"
  distillation_type: "uniform_random_resize" # either uniform_random_resize, **** 
  min_size: 320
  max_size: 420
  reload: True # whether to reload the teacher's supervision features or compute new ones 








